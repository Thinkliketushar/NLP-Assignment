{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e482c715",
   "metadata": {},
   "source": [
    "# 1. What are Corpora?\n",
    "Collection of all the documents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86810de",
   "metadata": {},
   "source": [
    "# 2. What are Tokens?\n",
    "instance of a sequence of characters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008b3627",
   "metadata": {},
   "source": [
    "# 3. What are Unigrams, Bigrams, Trigrams?\n",
    "- Uni grams consider each single word for counting; Bi grams considers two consecutive words at a time; We can have n grams similarly\n",
    "- Uni grams based BOW discards sequence of information; with n grams we can retain some of the sequence information\n",
    "- Dimensionality of the vector increases when including n grams;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2159590c",
   "metadata": {},
   "source": [
    "# 4. How to generate n-grams from text?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e301d628",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\tusha\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('this', 'is', 'a')\n",
      "('is', 'a', 'very')\n",
      "('a', 'very', 'good')\n",
      "('very', 'good', 'book')\n",
      "('good', 'book', 'to')\n",
      "('book', 'to', 'study')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.util import ngrams\n",
    " \n",
    "samplText='this is a very good book to study'\n",
    "NGRAMS=ngrams(sequence=nltk.word_tokenize(samplText), n=3)\n",
    "for grams in NGRAMS:\n",
    "    print(grams)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0e55d3",
   "metadata": {},
   "source": [
    "# 5.Explain Lemmatization\n",
    "Lemmatization takes lemma of a word based on its intended meaning depending on the context of surrounding words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd9ba75",
   "metadata": {},
   "source": [
    "# 6. Explain Stemming\n",
    "- Tastes, tasty and tasteful: indicate the same meaning which relates to taste;\n",
    "- With stemming we can combine words which have same root words;\n",
    "- Two of the algorithms are: Porter Stemmer and Snowball Stemmer;\n",
    "- Snowball stemmer is more powerful\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45db2c35",
   "metadata": {},
   "source": [
    "# 7. Explain Part-of-speech (POS) tagging\n",
    "POS tags make it possible for automatic text processing tools to take into account which part of speech each word is"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ecf2ce",
   "metadata": {},
   "source": [
    "# 8. Explain Chunking or shallow parsing\n",
    "Chunking is a process of extracting phrases from unstructured text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3638ad",
   "metadata": {},
   "source": [
    "# 9.Explain Noun Phrase (NP) chunking\n",
    "The Noun phrase extraction block extracts non-overlapping noun phrases from the input text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b151726",
   "metadata": {},
   "source": [
    "# 10. Explain Named Entity Recognition\n",
    "Named Entity Recognition (NER) is a process where a sentence or a chunk of text is parsed through to find entities that can be put under categories like names, organizations, locations, quantities, monetary values, percentages, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81608a3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
