{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c28a56a7",
   "metadata": {},
   "source": [
    "# 1 Can you think of a few applications for a sequence-to-sequence RNN? What about a sequence-to-vector RNN? And a vector-to-sequence RNN?\n",
    "application:- chatbot, question-answer, text summarization, machine translation, etc. It is like a encoder-decoder model which first we have a temporal information and we condense it down to a vector which we can call it a “concept vector”. The RNN model takes a single vector as input and produces a sequence as output called vector to sequence rnn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04d03a9",
   "metadata": {},
   "source": [
    "# 2. Why do people use encoder–decoder RNNs rather than plain sequence-to-sequence RNNs for automatic translation?\n",
    "the last words of a sentence can affect the first words of the translation, so you need to wait until you have heard the whole sentence before translating it. thats why we use encoder- decoder instead of sequence to sequence.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b7eb43",
   "metadata": {},
   "source": [
    "# 3. How could you combine a convolutional neural network with an RNN to classify videos?\n",
    "Each video is converted into sequential images and passed onto the CNN."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065a3464",
   "metadata": {},
   "source": [
    "# 4. What are the advantages of building an RNN using dynamic_rnn() rather than static_rnn()?\n",
    "It uses a tf.While loop to dynamically construct the graph when it is executed. That means graph creation is faster and you can feed batches of variable size."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1097afcc",
   "metadata": {},
   "source": [
    "# 5. How can you deal with variable-length input sequences?What about variable-length output sequences?\n",
    "The first and simplest way of handling variable length input is to set a special mask value in the dataset, and pad out the length of each input to the standard length with this mask value set for all additional entries created. Then, create a Masking layer in the model, placed ahead of all downstream layers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5eedc8",
   "metadata": {},
   "source": [
    "# 6. What is a common way to distribute training and execution of a deep RNN across multiple GPUs?\n",
    "MirroredStrategy supports synchronous distributed training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff7de2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
