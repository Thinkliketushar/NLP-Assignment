{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0c7aca4",
   "metadata": {},
   "source": [
    "# What are Sequence-to-sequence models?\n",
    "RNN is trained to map an input sequence to an output sequence which is not necessarily of the same length."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7c77dc",
   "metadata": {},
   "source": [
    "# 2. What are the Problem with Vanilla RNNs?\n",
    "vanishing gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe15c01",
   "metadata": {},
   "source": [
    "# 3. What is Gradient clipping?\n",
    "This helps gradient descent to have a reasonable behaviour even if the loss landscape of the model is irregular."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4040723",
   "metadata": {},
   "source": [
    "# 4. Explain Attention mechanism\n",
    "The attention mechanism is a part of a neural architecture that enables to dynamically highlight relevant features of the input data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da614f5f",
   "metadata": {},
   "source": [
    "# 5. Explain Conditional random fields (CRFs)\n",
    "Conditional random fields (CRFs) are a class of statistical modeling methods often applied in pattern recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d808d219",
   "metadata": {},
   "source": [
    "# 6. Explain self-attention\n",
    "the self-attention mechanism allows the inputs to interact with each other (“self”) and find out who they should pay more attention to (“attention”)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c4dfbc",
   "metadata": {},
   "source": [
    "# 7. What is Bahdanau Attention?\n",
    "an attention mechanism that learns to align and translate jointly in encoder and decorder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160264ae",
   "metadata": {},
   "source": [
    "# 8. What is a Language Model?\n",
    "Language modeling (LM) is the use of various statistical and probabilistic techniques to determine the probability of a given sequence of words occurring in a sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24566e1c",
   "metadata": {},
   "source": [
    "# 9. What is Multi-Head Attention?\n",
    "Multi-head Attention is a module for attention mechanisms which runs through an attention mechanism several times in parallel."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d03aee4",
   "metadata": {},
   "source": [
    "# 10. What is Bilingual Evaluation Understudy (BLEU)\n",
    "BLEU (BiLingual Evaluation Understudy) is a metric for automatically evaluating machine-translated text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b58052",
   "metadata": {},
   "outputs": [],
   "source": [
    "s"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
